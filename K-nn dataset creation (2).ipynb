{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36de654a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for loading 2 for training 3 for predicting2\n",
      "[22  2 28 ... 22  1  2] 98.905570366213  %\n",
      "Enter 1 for loading 2 for training 3 for predicting1\n",
      "Enter labelalphabet_L\n",
      "29\n",
      "\n",
      "Continue?0\n",
      "Enter 1 for loading 2 for training 3 for predicting2\n",
      "[20 24 22 ... 10  1 16] 98.96222498962224  %\n",
      "Enter 1 for loading 2 for training 3 for predicting1\n",
      "Enter labelalphabet_H\n",
      "30\n",
      "\n",
      "Continue?0\n",
      "Enter 1 for loading 2 for training 3 for predicting2\n",
      "[22  1 17 ...  1 22  0] 98.66935483870968  %\n",
      "Enter 1 for loading 2 for training 3 for predicting1\n",
      "Enter labelalphabet_F\n",
      "31\n",
      "\n",
      "Continue?0\n",
      "Enter 1 for loading 2 for training 3 for predicting2\n",
      "[21 20  7 ... 24 30  1] 98.76115625416278  %\n",
      "Enter 1 for loading 2 for training 3 for predicting1\n",
      "Enter labelalphabet_J\n",
      "32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import copy\n",
    "import argparse\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# timer.py\n",
    "\n",
    "\n",
    "class TimerError(Exception):\n",
    "    \"\"\"A custom exception used to report errors in use of Timer class\"\"\"\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self._start_time = None\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start a new timer\"\"\"\n",
    "        if self._start_time is not None:\n",
    "            raise TimerError(f\"Timer is running. Use .stop() to stop it\")\n",
    "\n",
    "        self._start_time = time.perf_counter()\n",
    "\n",
    "    def show(self):\n",
    "        \"\"\"Stop the timer, and report the elapsed time\"\"\"\n",
    "        if self._start_time is None:\n",
    "            raise TimerError(f\"Timer is not running. Use .start() to start it\")\n",
    "\n",
    "        elapsed_time = time.perf_counter() - self._start_time\n",
    "        return elapsed_time\n",
    "    def stop(self):\n",
    "        self._start_time=None\n",
    "\n",
    "# Function to calculate landmark list\n",
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # Iterate over each landmark point\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        # Convert normalized coordinates to pixel coordinates\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        # landmark_z = landmark.z  # Uncomment this line if you need the z-coordinate\n",
    "\n",
    "        # Append the pixel coordinates to the landmark_point list\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "\n",
    "# Function to preprocess landmarks\n",
    "def pre_process_landmark(landmark_list):\n",
    "    # Implement your preprocessing logic here\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(\n",
    "        itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list\n",
    "    pass\n",
    "\n",
    "# Initialize hands module\n",
    "\n",
    "\n",
    "# OpenCV VideoCapture\n",
    "while True:\n",
    "    mode=int(input(\"Enter 1 for loading 2 for training 3 for predicting\"))\n",
    "    if mode==3:\n",
    "        mp_hands = mp.solutions.hands\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "        hands = mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)\n",
    "        cap = cv2.VideoCapture(0)  # Use the appropriate index or video file path\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # BGR 2 RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Flip on horizontal\n",
    "            image = cv2.flip(image, 1)\n",
    "            debug_image = copy.deepcopy(image)\n",
    "\n",
    "            # Set flag\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Detections\n",
    "            results = hands.process(image)\n",
    "\n",
    "            # Set flag to true\n",
    "            image.flags.writeable = True\n",
    "\n",
    "            # RGB 2 BGR\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            with open(\"label.txt\",'r') as f:\n",
    "                label=f.read().split()\n",
    "            # Rendering results\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "                    landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "                    pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
    "                    x, y, w, h = cv2.boundingRect(np.array(landmark_list))\n",
    "                    cv2.rectangle(debug_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    hand_label = \"Left Hand\" if handedness.classification[0].label == \"Left\" else \"Right Hand\"\n",
    "                    cv2.putText(debug_image, hand_label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "                    mp_drawing.draw_landmarks(debug_image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                                                  mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                                  mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),\n",
    "                                                  )\n",
    "                data2 = pd.DataFrame([pre_processed_landmark_list])\n",
    "                xi = data2.iloc[:,:]\n",
    "                pred = knn.predict(xi)\n",
    "                # acc=knn.score()\n",
    "                op=label[int(pred)]\n",
    "                print(op)\n",
    "                time.sleep(1)\n",
    "                cv2.putText(debug_image,str(op), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 255, 255), 2)\n",
    "                time.sleep(1)\n",
    "                cv2.imshow('Hand Tracking', debug_image)\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        hands.close()\n",
    "    elif mode==2:\n",
    "        data=pd.read_csv('training_data.csv',header=None)\n",
    "        y=data.iloc[:,0]\n",
    "        x=data.iloc[:,1:]\n",
    "        xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25,random_state=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(xtrain,ytrain)\n",
    "        pred=knn.predict(xtest)\n",
    "        acc=knn.score(xtest,ytest)\n",
    "        print(pred,acc*100,\" %\")\n",
    "    elif mode==1:\n",
    "        mp_hands = mp.solutions.hands\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "        hands = mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)\n",
    "        cap = cv2.VideoCapture(0)  # Use the appropriate index or video file path\n",
    "        keyy = 1\n",
    "        t = Timer()\n",
    "        while keyy != 0:\n",
    "            label = input(\"Enter label\")\n",
    "            label=\" \"+label\n",
    "            with open(\"label.txt\",'r') as f:\n",
    "                la=f.read().split()\n",
    "                size=len(la)\n",
    "                print(size)\n",
    "            with open('label.txt','a+') as f:\n",
    "                print(f.read())\n",
    "                f.write(label)\n",
    "            t.start()\n",
    "            while t.show() < 120.0 and cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                # BGR 2 RGB\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Flip on horizontal\n",
    "                image = cv2.flip(image, 1)\n",
    "                debug_image = copy.deepcopy(image)\n",
    "\n",
    "                # Set flag\n",
    "                image.flags.writeable = False\n",
    "\n",
    "                # Detections\n",
    "                results = hands.process(image)\n",
    "\n",
    "                # Set flag to true\n",
    "                image.flags.writeable = True\n",
    "\n",
    "                # RGB 2 BGR\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                # Rendering results\n",
    "                if results.multi_hand_landmarks:\n",
    "                    for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "                        landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "                        l=pre_process_landmark(landmark_list)\n",
    "                        l.insert(0,size)\n",
    "                        #print(\"Iterations:\",l)\n",
    "                        #print(pre_processed_landmark_list)\n",
    "                        x, y, w, h = cv2.boundingRect(np.array(landmark_list))\n",
    "                        cv2.rectangle(debug_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                        hand_label = \"Left Hand\" if handedness.classification[0].label == \"Left\" else \"Right Hand\"\n",
    "                        cv2.putText(debug_image, hand_label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "                        mp_drawing.draw_landmarks(debug_image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                                                  mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                                  mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),\n",
    "                                                  )\n",
    "                        with open(\"training_data.csv\",'a+',newline='') as f:\n",
    "                            writer=csv.writer(f)\n",
    "                            #print(l)\n",
    "                            writer.writerow(l)   \n",
    "            keyy = int(input(\"Continue?\"))\n",
    "            t.stop()\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        hands.close()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "# Release the VideoCapture and hands objects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998921ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5f78bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
